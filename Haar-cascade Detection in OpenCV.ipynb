{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2 as ccc\n",
    "face_cascade = cv2.CascadeClassifier('/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/usr/share/opencv/haarcascades/haarcascade_eye.xml')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "caffe_root = '~/caffe/' \n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "DEMO_DIR = './DemoDir'\n",
    "\n",
    "categories = [ 'Angry' , 'Disgust' , 'Fear' , 'Happy'  , 'Neutral' ,  'Sad' , 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_emotion(input_image):\n",
    "    cur_net_dir = 'VGG_S_rgb'\n",
    "    images_repo = '.'\n",
    "\n",
    "    mean_filename=os.path.join(DEMO_DIR,cur_net_dir,'mean.binaryproto')\n",
    "    proto_data = open(mean_filename, \"rb\").read()\n",
    "    a = caffe.io.caffe_pb2.BlobProto.FromString(proto_data)\n",
    "    mean  = caffe.io.blobproto_to_array(a)[0]\n",
    "    mean = mean.mean(1).mean(1)\n",
    "\n",
    "    net_pretrained = os.path.join(DEMO_DIR,cur_net_dir,'EmotiW_VGG_S.caffemodel')\n",
    "    net_model_file = os.path.join(DEMO_DIR,cur_net_dir,'deploy.prototxt')\n",
    "    VGG_S_Net = caffe.Classifier(net_model_file, net_pretrained,\n",
    "                           mean=mean,\n",
    "                           channel_swap=(2,1,0),\n",
    "                           raw_scale=255,\n",
    "                           image_dims=(256, 256))\n",
    "\n",
    "#     input_image = caffe.io.load_image(os.path.join(images_repo,'happy.png'))\n",
    "    prediction = VGG_S_Net.predict([input_image],oversample=False)\n",
    "    return 'predicted category is {0}'.format(categories[prediction.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Sad\n",
      "predicted category is Happy\n",
      "predicted category is Fear\n",
      "predicted category is Fear\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Angry\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Fear\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Fear\n",
      "predicted category is Angry\n",
      "predicted category is Happy\n",
      "predicted category is Fear\n",
      "predicted category is Fear\n",
      "predicted category is Happy\n",
      "predicted category is Happy\n",
      "predicted category is Fear\n",
      "predicted category is Fear\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "wait_time = 100\n",
    "current = 0\n",
    "while(True):\n",
    "    current= (current + 1) % wait_time\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    temp_face = frame[x:x+w, y:y+h]\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if current == 0:\n",
    "        ccc.imshow('frame2',temp_face)\n",
    "        print(detect_emotion(temp_face))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
